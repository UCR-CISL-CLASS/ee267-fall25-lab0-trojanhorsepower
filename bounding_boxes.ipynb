{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5908a9bd",
   "metadata": {},
   "source": [
    "## 0. Set up the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea04776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "bp_lib = world.get_blueprint_library()\n",
    "\n",
    "# Get the map spawn points\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "# spawn vehicle\n",
    "vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "\n",
    "# spawn camera\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "# Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True # Enables synchronous mode\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# Create a queue to store and retrieve the sensor data\n",
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc3968",
   "metadata": {},
   "source": [
    "## 1. Geometric transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a285d",
   "metadata": {},
   "source": [
    "#### The `build_projection_matrix` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7531352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_projection_matrix(w, h, fov, is_behind_camera=False):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "\n",
    "    if is_behind_camera:\n",
    "        K[0, 0] = K[1, 1] = -focal\n",
    "    else:\n",
    "        K[0, 0] = K[1, 1] = focal\n",
    "\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7fee4",
   "metadata": {},
   "source": [
    "####  The `get_image_point` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa4f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_point(loc, K, w2c):\n",
    "        # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "        # Format the input coordinate (loc is a carla.Position object)\n",
    "        point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "        # transform to camera coordinates\n",
    "        point_camera = np.dot(w2c, point)\n",
    "\n",
    "        # New we must change from UE4's coordinate system to an \"standard\"\n",
    "        # (x, y ,z) -> (y, -z, x)\n",
    "        # and we remove the fourth componebonent also\n",
    "        point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "        # now project 3D->2D using the camera matrix\n",
    "        point_img = np.dot(K, point_camera)\n",
    "        # normalize\n",
    "        point_img[0] /= point_img[2]\n",
    "        point_img[1] /= point_img[2]\n",
    "\n",
    "        return point_img[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82168515",
   "metadata": {},
   "source": [
    "#### Set up the camera specifications and calculate the projection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac9fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the world to camera matrix\n",
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "# Get the attributes from the camera\n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_bp.get_attribute(\"fov\").as_float()\n",
    "\n",
    "# Calculate the camera projection matrix to project from 3D -> 2D\n",
    "K = build_projection_matrix(image_w, image_h, fov)\n",
    "K_b = build_projection_matrix(image_w, image_h, fov, is_behind_camera=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81eb6bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the first image\n",
    "world.tick()\n",
    "image = image_queue.get()\n",
    "\n",
    "# Reshape the raw data into an RGB array\n",
    "img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4)) \n",
    "\n",
    "# Display the image in an OpenCV display window\n",
    "cv2.namedWindow('ImageWindowName', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('ImageWindowName',img)\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c88e3",
   "metadata": {},
   "source": [
    "## 2. Implement vehicle bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4b0d4",
   "metadata": {},
   "source": [
    "#### Spawn additional vehicles in the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4134ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle'))\n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "    if npc:\n",
    "        npc.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf61163",
   "metadata": {},
   "source": [
    "- Spawning 1000 vehicles in the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e8403",
   "metadata": {},
   "source": [
    "#### Modified game loop to draw the vehicle bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10cec85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_canvas(pos, img_h, img_w):\n",
    "    \"\"\"Return true if point is in canvas\"\"\"\n",
    "    if (pos[0] >= 0) and (pos[0] < img_w) and (pos[1] >= 0) and (pos[1] < img_h):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Remember the edge pairs\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "\n",
    "while True:\n",
    "    # Retrieve and reshape the image\n",
    "    world.tick()\n",
    "    image = image_queue.get()\n",
    "\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "    # Get the camera matrix \n",
    "    world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "\n",
    "        # Filter out the ego vehicle\n",
    "        if npc.id != vehicle.id:\n",
    "\n",
    "            bb = npc.bounding_box\n",
    "            dist = npc.get_transform().location.distance(vehicle.get_transform().location)\n",
    "\n",
    "            # Filter for the vehicles within 60m\n",
    "            if dist < 60:\n",
    "\n",
    "            # Calculate the dot product between the forward vector\n",
    "            # of the vehicle and the vector between the vehicle\n",
    "            # and the other vehicle. We threshold this dot product\n",
    "            # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "                forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "                ray = npc.get_transform().location - vehicle.get_transform().location\n",
    "\n",
    "                if forward_vec.dot(ray) > 0:\n",
    "                    verts = [v for v in bb.get_world_vertices(npc.get_transform())]\n",
    "                    for edge in edges:\n",
    "                        p1 = get_image_point(verts[edge[0]], K, world_2_camera)\n",
    "                        p2 = get_image_point(verts[edge[1]],  K, world_2_camera)\n",
    "\n",
    "                        p1_in_canvas = point_in_canvas(p1, image_h, image_w)\n",
    "                        p2_in_canvas = point_in_canvas(p2, image_h, image_w)\n",
    "\n",
    "                        if not p1_in_canvas and not p2_in_canvas:\n",
    "                            continue\n",
    "\n",
    "                        ray0 = verts[edge[0]] - camera.get_transform().location\n",
    "                        ray1 = verts[edge[1]] - camera.get_transform().location\n",
    "                        cam_forward_vec = camera.get_transform().get_forward_vector()\n",
    "\n",
    "                        # One of the vertex is behind the camera\n",
    "                        if not (cam_forward_vec.dot(ray0) > 0):\n",
    "                            p1 = get_image_point(verts[edge[0]], K_b, world_2_camera)\n",
    "                        if not (cam_forward_vec.dot(ray1) > 0):\n",
    "                            p2 = get_image_point(verts[edge[1]], K_b, world_2_camera)\n",
    "\n",
    "                        cv2.line(img, (int(p1[0]),int(p1[1])), (int(p2[0]),int(p2[1])), (255,0,0, 255), 1)        \n",
    "\n",
    "    cv2.imshow('ImageWindowName',img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c062d7",
   "metadata": {},
   "source": [
    "## 3. Export bounding boxes for Pascal VOC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851f975",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m frame_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/\u001b[39m\u001b[38;5;132;01m%06d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m image\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Save the image\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Initialize the exporter\u001b[39;00m\n\u001b[1;32m     19\u001b[0m writer \u001b[38;5;241m=\u001b[39m Writer(frame_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, image_w, image_h)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pascal_voc_writer import Writer\n",
    "\n",
    "while True:\n",
    "    # Retrieve the image\n",
    "    world.tick()\n",
    "    image = image_queue.get()\n",
    "\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "    # Get the camera matrix \n",
    "    world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "    frame_path = 'output/part04/%06d' % image.frame\n",
    "\n",
    "    # Save the image\n",
    "    image.save_to_disk(frame_path + '.png')\n",
    "\n",
    "    # Initialize the exporter\n",
    "    writer = Writer(frame_path + '.png', image_w, image_h)\n",
    "\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "        if npc.id != vehicle.id:\n",
    "            bb = npc.bounding_box\n",
    "            dist = npc.get_transform().location.distance(vehicle.get_transform().location)\n",
    "            if dist < 50:\n",
    "                forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "                ray = npc.get_transform().location - vehicle.get_transform().location\n",
    "                if forward_vec.dot(ray) > 0:\n",
    "                    p1 = get_image_point(bb.location, K, world_2_camera)\n",
    "                    verts = [v for v in bb.get_world_vertices(npc.get_transform())]\n",
    "                    x_max = -10000\n",
    "                    x_min = 10000\n",
    "                    y_max = -10000\n",
    "                    y_min = 10000\n",
    "                    for vert in verts:\n",
    "                        p = get_image_point(vert, K, world_2_camera)\n",
    "                        if p[0] > x_max:\n",
    "                            x_max = p[0]\n",
    "                        if p[0] < x_min:\n",
    "                            x_min = p[0]\n",
    "                        if p[1] > y_max:\n",
    "                            y_max = p[1]\n",
    "                        if p[1] < y_min:\n",
    "                            y_min = p[1]\n",
    "\n",
    "                    # Add the object to the frame (ensure it is inside the image)\n",
    "                    if x_min > 0 and x_max < image_w and y_min > 0 and y_max < image_h: \n",
    "                        writer.addObject('vehicle', x_min, y_min, x_max, y_max)\n",
    "\n",
    "                    cv2.line(img, (int(x_min),int(y_min)), (int(x_max),int(y_min)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_min),int(y_max)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_min),int(y_min)), (int(x_min),int(y_max)), (0,0,255, 255), 1)\n",
    "                    cv2.line(img, (int(x_max),int(y_min)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "\n",
    "    # Save the bounding boxes in the scene\n",
    "    writer.save(frame_path + '.xml')\n",
    "\n",
    "    cv2.imshow('ImageWindowName',img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448432cc",
   "metadata": {},
   "source": [
    "- To review the annotated data in PASCAL VOC format look `output` directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trojan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
